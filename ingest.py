import os
import re
import shutil
import subprocess
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter, Language
from langchain_community.vectorstores import Chroma
from langchain_ollama import OllamaEmbeddings

# ä»£ç†é…ç½®
os.environ["NO_PROXY"] = "localhost,127.0.0.1"

# é…ç½®ï¼šæ”¯æŒä»ç¯å¢ƒå˜é‡è¯»å– Ollama åœ°å€ (Docker éƒ¨ç½²æ—¶ä½¿ç”¨)
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://127.0.0.1:11434")
EMBED_MODEL = "nomic-embed-text"
# æ ¹å­˜å‚¨ç›®å½•
DB_ROOT = "chroma_db_store"
SOURCE_ROOT = "source_code"

# ==========================================
# ğŸ›¡ï¸ å®‰å…¨ï¼šGitHub URL éªŒè¯
# ==========================================
def is_valid_git_url(url):
    """
    éªŒè¯ Git ä»“åº“ URL æ ¼å¼ï¼Œé˜²æ­¢å‘½ä»¤æ³¨å…¥
    æ”¯æŒ GitHub, GitLab, Gitee ç­‰ä¸»æµå¹³å°
    """
    # å…è®¸çš„ Git URL æ¨¡å¼
    patterns = [
        r'^https?://github\.com/[\w\-\.]+/[\w\-\.]+/?$',
        r'^https?://gitlab\.com/[\w\-\.]+/[\w\-\.]+/?$',
        r'^https?://gitee\.com/[\w\-\.]+/[\w\-\.]+/?$',
        r'^https?://bitbucket\.org/[\w\-\.]+/[\w\-\.]+/?$',
        r'^git@github\.com:[\w\-\.]+/[\w\-\.]+\.git$',
    ]
    
    for pattern in patterns:
        if re.match(pattern, url.strip()):
            return True
    return False

def get_project_name(url):
    """ä» GitHub URL æå–é¡¹ç›®åç§°"""
    return url.split("/")[-1].replace(".git", "")

def clone_repo(url, target_dir):
    """å…‹éš†æˆ–æ›´æ–°ä»£ç åº“"""
    # å¦‚æœç›®å½•å­˜åœ¨ï¼Œå…ˆåˆ é™¤ï¼ˆç¡®ä¿å¹²å‡€çš„å…‹éš†ï¼‰
    if os.path.exists(target_dir):
        print(f"âš ï¸ æ­£åœ¨æ¸…ç†æ—§ç›®å½• {target_dir} ä»¥è¿›è¡Œé‡æ–°å…‹éš†...")
        try:
            shutil.rmtree(target_dir)
        except Exception as e:
            print(f"âš ï¸ åˆ é™¤å¤±è´¥ (å¯èƒ½è¢«å ç”¨): {e}")

    print(f"â¬‡ï¸ æ­£åœ¨å…‹éš† {url}...")
    try:
        subprocess.run(["git", "clone", url, target_dir], check=True)
        return True
    except Exception as e:
        print(f"âŒ å…‹éš†å¤±è´¥: {e}")
        return False

def ingest_project(project_url, force_update=False):
    """
    ä¸»å…¥å£
    :param project_url: GitHub åœ°å€
    :param force_update: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½å¹¶å‘é‡åŒ–
    """
    # ğŸ›¡ï¸ å®‰å…¨æ£€æŸ¥ï¼šéªŒè¯ URL æ ¼å¼
    if not is_valid_git_url(project_url):
        print(f"âŒ æ— æ•ˆçš„ Git URL: {project_url}")
        return None, "Invalid URL: Only GitHub/GitLab/Gitee/Bitbucket URLs are allowed"
    
    project_name = get_project_name(project_url)
    
    source_path = os.path.join(SOURCE_ROOT, project_name)
    db_path = os.path.join(DB_ROOT, project_name)
    
    print(f"ğŸš€ å¼€å§‹å¤„ç†é¡¹ç›®: {project_name}")

    # --- [å…³é”®ä¼˜åŒ–] æ™ºèƒ½ç¼“å­˜æ£€æŸ¥ ---
    # å¦‚æœæ•°æ®åº“å­˜åœ¨ï¼Œä¸”ç”¨æˆ·æ²¡æœ‰è¦æ±‚å¼ºåˆ¶æ›´æ–°ï¼Œç›´æ¥è¿”å›ç°æœ‰æ•°æ®åº“
    if os.path.exists(db_path) and not force_update:
        print(f"âœ… å‘ç°ç°æœ‰å‘é‡åº“: {db_path}")
        print(f"â© è·³è¿‡ä¸‹è½½ä¸è®¡ç®—ï¼Œç›´æ¥åŠ è½½ç¼“å­˜ã€‚")
        return db_path, "Cached: Loaded existing database"

    # --- ä»¥ä¸‹æ˜¯åŸæœ‰é€»è¾‘ (ä¸‹è½½ + è®¡ç®—) ---
    
    # 1. ä¸‹è½½ä»£ç 
    if not clone_repo(project_url, source_path):
        return None, "Clone Failed"

    # 2. åŠ è½½æ–‡ä»¶
    print("ğŸ“‚ æ­£åœ¨æ‰«ææ–‡ä»¶...")
    documents = []
    # å¢åŠ äº†ä¸€äº›å¸¸è§åç¼€
    file_patterns = ["**/*.py", "**/*.md", "**/*.js", "**/*.ts", "**/*.java", "**/*.go", "**/*.txt", "**/*.yaml"]
    
    for pattern in file_patterns:
        try:
            loader = DirectoryLoader(
                source_path, glob=pattern, loader_cls=TextLoader,
                silent_errors=True,
                loader_kwargs={'encoding': 'utf-8', 'autodetect_encoding': True}
            )
            documents.extend(loader.load())
        except Exception:
            pass
            
    if not documents:
        return None, "No Documents Found"

    # 3. åˆ‡åˆ†
    print("âœ‚ï¸ æ­£åœ¨åˆ‡åˆ†...")
    splitter = RecursiveCharacterTextSplitter.from_language(
        language=Language.PYTHON, chunk_size=1500, chunk_overlap=200
    )
    chunks = splitter.split_documents(documents)
    
    # 4. å‘é‡åŒ– (å¦‚æœæœ‰æ—§åº“ï¼Œå…ˆæ¸…ç†ï¼Œé˜²æ­¢æ•°æ®é‡å¤å åŠ )
    if os.path.exists(db_path):
        shutil.rmtree(db_path)

    print(f"ğŸ’¾ æ­£åœ¨è®¡ç®—å‘é‡å¹¶å­˜å…¥: {db_path}...")
    embeddings = OllamaEmbeddings(
        model=EMBED_MODEL,
        base_url=OLLAMA_BASE_URL
    )
    
    vector_store = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        persist_directory=db_path
    )
    
    return db_path, f"Success: Processed {len(chunks)} new chunks"

def list_existing_projects():
    """åˆ—å‡ºå·²ç»å­˜åœ¨çš„é¡¹ç›®æ•°æ®åº“"""
    if not os.path.exists(DB_ROOT):
        os.makedirs(DB_ROOT)
        return []
    # æ‰«ææ–‡ä»¶å¤¹ï¼Œåªè¿”å›ç›®å½•å
    projects = [d for d in os.listdir(DB_ROOT) if os.path.isdir(os.path.join(DB_ROOT, d))]
    return projects
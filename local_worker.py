import os
from langchain_community.vectorstores import Chroma
from langchain_ollama import OllamaEmbeddings, ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser

os.environ["NO_PROXY"] = "localhost,127.0.0.1"


# é…ç½®ï¼šæ”¯æŒä»ç¯å¢ƒå˜é‡è¯»å– Ollama åœ°å€ (Docker éƒ¨ç½²æ—¶ä½¿ç”¨)
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://127.0.0.1:11434")
EMBED_MODEL = "nomic-embed-text"
LOCAL_LLM = "qwen2.5:7b"


def get_retriever(db_path):
    """
    å·¥å‚å‡½æ•°ï¼šæ ¹æ®æ•°æ®åº“è·¯å¾„ï¼Œè¿”å›ä¸€ä¸ªæ–°çš„æ£€ç´¢å™¨
    """
    print(f"ğŸ”Œ [Local Worker] æ­£åœ¨è¿æ¥çŸ¥è¯†åº“: {db_path}")
    embeddings = OllamaEmbeddings(
        model=EMBED_MODEL,
        base_url=OLLAMA_BASE_URL
    )
    vectorstore = Chroma(
        persist_directory=db_path, 
        embedding_function=embeddings
    )
    # æ‰©å¤§æœç´¢èŒƒå›´åˆ° 50
    return vectorstore.as_retriever(search_kwargs={"k": 50})

def get_grader_chain():
    """è¿”å›è¯„åˆ†é“¾å¯¹è±¡ (æ— çŠ¶æ€ï¼Œå¯å¤ç”¨)"""
    llm = ChatOllama(
        model=LOCAL_LLM, 
        temperature=0, 
        format="json",
        base_url=OLLAMA_BASE_URL
    )

    # ä¼˜åŒ–åçš„ Promptï¼šæ›´å®½å®¹çš„è¯„åˆ†ç­–ç•¥ + ä¸‰çº§è¯„åˆ†
    prompt = ChatPromptTemplate.from_template(
        """ä½ æ˜¯ä¸€ä¸ªå®½å®¹çš„æ–‡æ¡£ç›¸å…³æ€§è¯„åˆ†å‘˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ¤æ–­æ–‡æ¡£æ˜¯å¦å¯èƒ½å¯¹å›ç­”é—®é¢˜æœ‰å¸®åŠ©ã€‚

è¯„åˆ†æ ‡å‡†ï¼ˆè¯·å€¾å‘äºä¿ç•™æ–‡æ¡£ï¼‰ï¼š
- "yes": æ–‡æ¡£**ç›´æ¥ç›¸å…³**ï¼ŒåŒ…å«èƒ½å›ç­”é—®é¢˜çš„å…³é”®ä¿¡æ¯
- "partial": æ–‡æ¡£**é—´æ¥ç›¸å…³**ï¼ŒåŒ…å«èƒŒæ™¯ä¿¡æ¯ã€ç›¸å…³æ¦‚å¿µã€æˆ–å¯èƒ½æœ‰ç”¨çš„ä¸Šä¸‹æ–‡
- "no": æ–‡æ¡£**å®Œå…¨æ— å…³**ï¼Œä¸é—®é¢˜æ¯«æ— å…³è”

é‡è¦æç¤ºï¼š
1. å¦‚æœæ–‡æ¡£æ¥è‡ªåŒä¸€é¡¹ç›®/ä»£ç åº“ï¼Œå€¾å‘äºè¯„ä¸º "partial" è€Œé "no"
2. ä»£ç æ–‡ä»¶ä¸­çš„å‡½æ•°åã€ç±»åã€å˜é‡åå¦‚æœä¸é—®é¢˜ç›¸å…³ï¼Œåº”è¯„ä¸º "yes" æˆ– "partial"
3. READMEã€é…ç½®æ–‡ä»¶ã€æ³¨é‡Šé€šå¸¸åŒ…å«æœ‰ç”¨ä¸Šä¸‹æ–‡ï¼Œå€¾å‘äºä¿ç•™

å¿…é¡»è¾“å‡ºä¸¥æ ¼çš„ JSON æ ¼å¼ï¼š
{{ "score": "yes" }} æˆ– {{ "score": "partial" }} æˆ– {{ "score": "no" }}

é—®é¢˜: {question}
æ–‡æ¡£: {document}
JSON è¾“å‡º:
"""
    )
    return prompt | llm | JsonOutputParser()